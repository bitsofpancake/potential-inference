<!doctype html>
<html>
	<head>
		<title>Inferring the Gravitational Potential of the Milky Way - Casey Chu</title>
		<link href="poster.css" type="text/css" rel="stylesheet" />
		<link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.3.0/katex.min.css" type="text/css" rel="stylesheet" />
	</head>
	<body>
		<div id="background"></div>
	
		<header>
			<h1>Inferring the Gravitational Potential of the Milky Way</h1>
			<div class="author">Casey Chu<sup>1,2</sup>, Yoram Lithwick<sup>1</sup>, Fabio Antonini<sup>1</sup></div>
			<div class="insitutions"><sup>1</sup>Northwestern University, <sup>2</sup>Harvey Mudd College</div>
		</header>
		
		<main>
			<article style="margin-bottom: 0.5in">
				<h2>How do we study something we can't see?</h2>
				
				<p>One way to study dark matter is to observe its effect on visible objects: stars. In particular, the distribution of dark matter in our galaxy generates a gravitational potential that affects the motion of the stars we observe.</p>
				
				<p>The spacecraft <i>Gaia</i> is currently recording the position and velocity of one billion stars in the Milky Way (Perryman et al. 2001), so we are in perfect position to take advantage of this information about the gravitational potential that is statistically encoded in the motion of the stars.</p>
				
				<p>We've created a simple, numerical algorithm to extract the gravitational potential from <i>Gaia</i>-like data. Given a set of observed positions and velocities of particles (stars), we are able to infer the potential in which they are traveling.</p>
			</article>
			
			<article style="margin-bottom: 0.25em">
				<h2>The fundamental assumption: phase-mixing</h2>
				
				<p>The algorithm we developed relies on the system being <em>phase-mixed</em>. Figure 1 depicts the phase-mixing of 200 particles that are initially close together in phase space, evolving in a potential of <var>\Phi(x) = \frac{1}{2}|x|^\alpha</var> for <var>\alpha = 1.5</var>.</p>
				
				<figure>
					<!--video controls>
						<source src="images/phase_mixing.webm" type="video/webm" />
					</video-->
					<img src="images/evolution_0.svg" />
					<img src="images/evolution_1.svg" />
					<img src="images/evolution_2.svg" />
					<img src="images/evolution_3.svg" />
					<img src="images/evolution_4.svg" />
					<img src="images/evolution_5.svg" />
					<figcaption>The phase-mixing of 200 particles. The arrows<br />trace the phase-space flow generated by the potential.</figcaption>
				</figure>
				
				<p>Notice that as time progresses, the particles approach a configuration that is macroscopically steady-state, or phase-mixed.</p>

				<p>One important property of phase-mixing is that if we evolve the <em>same</em> set of particles under <em>different</em> potentials (e.g., different values of <var>\alpha</var>), then the particles evolve to <em>different</em> steady-state configurations.</p>
				<!--
				<p>Figure 2 depicts an important property of phase-mixing: the <em>same</em> set of particles evolve to <em>different</em> steady-state "shapes" when they are evolved under different potentials (e.g., different values of <var>\alpha</var>).</p>
				
				<figure>
					<img src="images/evolved_1.5.svg" />
					<img src="images/evolved_1.8.svg" />
					<img src="images/evolved_2.5.svg" />
					<figcaption>Steady-state configurations for different potentials.</figcaption>
				</figure>
				
				<p>This property, that different potentials produce different steady-state configurations, is crucial to our method.</p>
-->
			</article>
			
			<article style="background: none; margin: 0 0.5em; color: rgba(255, 255, 255, 0.9); font-size: 0.8em; flex: 1">
				<b>Below:</b> A star map generated from preliminary Gaia<br /> data. Source: ESA/Gaia (CC BY-SA 3.0 IGO).
			</article>
			
			<article>
				<h2>The insight behind the inference algorithm</h2>
				
				<!--figure class="float" style="width: 360px; margin-top: 0.75em">
					<img src="images/unknown.svg" />
					<figcaption>A sample data set: particles observed from an unknown potential.[consider strongly getting rid of]</figcaption>
				</figure-->
				
				<!--p>Suppose that we are given the positions and velocities of particles taken from an unknown potential. Our aim is to guess which potential these particles come from.</p-->
				<p>Let's assume that we know that the particles we observe are in a steady-state configuration. Then:</p>
				
			<ul>
				<li>If we evolve the particles under the <em>correct</em> potential, they will remain in the <em>same, steady-state configuration</em>.</li>
				<li>Conversely, if we evolve them under an <em>incorrect</em> potential, they will evolve towards a <em>different configuration</em>.</li>
			</ul>
			
				<!--p>Using this insight, one algorithm to infer the correct potential from a set of observations of particles is to simply to guess a bunch of different potentials, evolve the observed particles under each of these trial potentials, and see which potential best preserves the original configuration.</p-->
				
				<p>We demonstrate this in Figure 2, where a set of particles, drawn from an unknown potential, is evolved under three different trial potentials (different values of <var>\alpha</var>).</p>
				
				<figure>
					<!--
					<video controls loop style="width: 100%">
						<source src="images/evolution.webm" type="video/webm" />
					</video>-->
					<img src="images/comparison0_1.5.svg" />
					<img src="images/comparison10_1.5.svg" />
					<img src="images/comparison100_1.5.svg" />
					<img src="images/comparison0_1.8.svg" />
					<img src="images/comparison10_1.8.svg" />
					<img src="images/comparison100_1.8.svg" />
					<img src="images/comparison0_2.5.svg" />
					<img src="images/comparison10_2.5.svg" />
					<img src="images/comparison100_2.5.svg" />
					<figcaption>The evolution of observed particles under different potentials.</figcaption>
				</figure>
				
				<p>In this simple example, since the configuration of the particles evolved under the <var>\alpha = 1.5</var> potential most resembles the original, observed distribution, we may infer that the particles most likely come from an <var>\alpha = 1.5</var> potential.</p>
			</article>
			
			<!--article>
				<h2>Mathematical derivation</h2>
				
				<p>Rather than simply choosing the best potential by eye, let us quantify how good a trial potential is, i.e. how close an evolved configuration is to the observed particles. Let's assign a "likelihood" score to each trial potential, with higher scores corresponding to closer configurations.</p>
				
				<p>
					First, we define a function that encodes the distribution of our observed particles after having been evolved for a time <var>t</var> under a potential <var>\Phi</var>. We use a technique called <a href="https://en.wikipedia.org/wiki/Kernel_density_estimation" target="_blank">kernel density estimation</a> to approximate the phase-space density at time <var>t</var>; define a function <var>f</var> to be
					<code>f(x,v;t \,|\, \Phi) = \sum_i K(x_i(t) - x)\, K(v_i(t) - v),</code>
					where <var>x_i(t)</var> and <var>v_i(t)</var> denote the position and velocity of the <var>i</var>th particle evolved to time <var>t</var> under the potential <var>\Phi</var>, and <var>K(\cdot)</var> is a <em>kernel</em>, a function that is non-zero only around <var>0</var>. For example, a typical kernel is a Gaussian centered at <var>0</var>. The result is that this function <var>f(x,v;t\,|\,\Phi)</var> gives an approximation to the phase-space density of particles at <var>x</var> and <var>v</var> and time <var>t</var>.
				</p>
				
				<p>
					Next, we define a time-averaged version of <var>f</var>:
					<code>f(x,v \,|\, \Phi) = \frac{1}{T}\int_0^T f(x,v;t\,|\,\Phi) \,dt.</code>
					This approximates the steady-state phase-space density of particles evolved under a potential <var>\Phi</var>.
				</p>
				
				<p>If <var>f</var> is properly normalized, we can treat this density function as a probability distribution function. Then the probability of observing the positions and velocities we observed assuming a particular potential is
					<code>
						\Pr(x_1,v_1,\ldots,x_n,v_n\,|\,\Phi) = \prod_i f(x_i, v_i \,|\, \Phi),
					</code>
					assuming that the particles were drawn independently.
				</p>
				
				<p>This allows us to assign a score to different trial potentials, based on our observed data, using <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem" target="_blank">Bayes' theorem</a>:
					<code>
						\Pr(\Phi \,|\, x_1,v_1,\ldots,x_n,v_n) \propto \Pr(\Phi)\,\Pr(x_1,v_1,\ldots,x_n,v_n\,|\,\Phi).
					</code>
					The factor of <var>\Pr(\Phi)</var> is called the <em>prior distribution</em> of <var>\Phi</var>, which is negligible in many cases. This final function is called the <em>posterior distribution</em> of <var>\Phi</var> (or simply, the posterior), and it satisfies our original goal: it's greatest for the most probable trial potentials!
				</p>
			</article-->
			<article>
				<h2>The likelihood function</h2>
				<p>Instead of choosing the best potential by eye, we can construct a function <var>L</var> that quantifies how well a trial potential preserves the original configuration.</p>
				
				<p>Let <var>x_1</var>, <var>v_1</var>, <var>\ldots</var>, <var>x_n</var>, <var>v_n</var> be a set of <var>n</var> observed positions and velocities. Then the <em>likelihood</em> that these observations came from a particular potential <var>\Phi</var> is
					<code>
						L(\Phi \,|\, x_1,v_1,\ldots,x_n,v_n) = \prod_i f(x_i, v_i \,|\, \Phi),
					</code>
					where we've defined
					<code>
						f(x,v \,|\, \Phi) = \frac{1}{nT}\int_0^T\sum_i K(x_i(t) - x)\,K(v_i(t) - v) \,dt,
					</code>
					where <var>x_i(t)</var> and <var>v_i(t)</var> denote the position and velocity of the <var>i</var>th particle evolved to time <var>t</var> under the potential <var>\Phi</var>, and <var>K(\cdot)</var> is a <em>kernel function</em>, e.g., a Gaussian centered at <var>0</var>. This function <var>L</var> is greatest for potentials that preserve the original configuration.
				</p>
			</article>
			
			<article style="background-color: rgba(255, 255, 255, 0.3); margin-top: 0">
				<p class="acknowledgement">This material is based upon work supported by the National Science Foundation under Grant No. AST-1359462, a Research Experiences for Undergraduates (REU) grant awarded to CIERA at Northwestern University. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.</p>
			</article>
			
			<article style="padding-bottom: 1em">
				<h2>Summary of the algorithm</h2>
				
				<p>Our algorithm to infer the potential from a set of observed positions and velocities is as follows.</p>
				
				<ol>
					<li><em>Guess a trial potential</em> by choosing a set of values for the parameters of a potential, e.g., via a Monte Carlo method.</li>
					<li><em>Calculate the likelihood</em> of observing the data under the chosen potential, according to the formula in the previous section.</li>
					<li><em>Repeat</em> steps 1&ndash;2 until convergence of the likelihood. The most likely potential has the parameters with the greatest likelihood.</li>
				</ol>
			</article>
			
			<article style="padding-bottom: 1em">
				<h2>A two-dimensional test case</h2>
				
				<figure class="float" style="width: 400px; margin-top: 0.75em; margin-right: -0.3em; margin-left: 0.5em">
					<img src="images/logarithmic.svg" />
					<figcaption>A contour plot of the likelihood of the parameters. Red is higher; contours are at <var>2^{-2^i}</var> for <var>i=0,\ldots,13</var>.</figcaption>
				</figure>
				
				<p>We have tested the algorithm for the two-dimensional <em>logarithmic potential</em> given by
					<code>\Phi(x,y) = \log(x^2 + \frac{y^2}{q^2} + R_c^2),</code>					
					where <var>q</var> and <var>R_c</var> are parameters that describe the shape of the potential. It is a simple model for real galaxies.</p>
				
				
				<!--figure style="width: 400px">
					<video controls loop style="width: 100%">
						<source src="images/logarithmic_potential.webm" type="video/webm" />
					</video>
					<figcaption>"Stars" in a logarithmic potential.</figcaption>
				</figure-->
				
				<p>We simulated <var>n = 10^4</var> particles in the logarithmic potential with true parameters of <var>q^2=0.8</var> and <var>R_c^2=1.5</var>. Figure 3 depicts the likelihood we calculated. It peaks near the true values of the parameters, indicating that the algorithm was successful.</p>
			</article>
			
			<article style="padding-bottom: 1em">
				<h2>Advantages and future work</h2>
				
				<p>Our method has two novel advantages over existing methods <span class="cite">(e.g., Bovy et al. 2010, Magorrian 2014, Han et al. 2015)</span>:
					<ul>
						<li><b>General:</b> This algorithm requires only that the particles are in steady-state, whereas some other methods require also that the potential be integrable.</li>
						<li><b>Intuitive:</b> It has an intuitive interpretation in terms of phase-mixing.</li>
					</ul>
				</p>
				
				<p>
					Nevertheless, there are several challenges that should be addressed before applying the algorithm to <i>Gaia</i> data:
					<ul>
						<li><b>Computation time:</b> An application to <var>10^9</var> particles will be computationally expensive.</li>
						<li><b>Noise:</b> The likelihood function is currently quite noisy, which may prevent accurate inference of parameters.</li>
						<li><b>Lack of error bounds:</b> It's currently unclear how to accurately quantify the uncertainty in the inferred parameters.</li>
					</ul>
				</p>
			</article>
			
			<article>
				<h2>Contact information and further reading</h2>
				
				<p><img src="images/casey.jpg" style="float: right; width: 185px; margin: 0.15em 0.5em 0 1em" />For questions or comments, please contact Casey Chu at <tt>cchu@hmc.edu</tt>. Code written in C++ and a derivation of the likelihood function is available at <tt>bitsofpancake.github.io/potential-inference</tt>.</p>
			</article>
			
			<article style="background-color: rgba(255, 255, 255, 0.3)">
				<ul class="citations">
					<li>Binney &amp; Tremaine, 2008, <cite>Galactic Dynamics: Second Edition</cite>.</li>
					<li>Bovy et al., 2010, ApJ, 711, 1157.</li>
					<li>Han et al., 2015, arXiv:1507.00769 (pre-print).</li>
					<li>Magorrian, 2014, MNRAS, 437, 2230.</li>
					<li>Perryman et al., 2001, A&amp;A, 369, 339.</li>
				</ul>
			</article>
		</main>

		</footer>
		
		<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.3.0/katex.min.js"></script>
		<script type="text/javascript">
			[].forEach.call(document.querySelectorAll('var, code'), function (el) {
				katex.render(el.innerHTML, el, { displayMode: el.tagName === 'CODE' });
			});
		</script>
		<script type="text/javascript" src="http://smartquotesjs.com/src/smartquotes.min.js"></script>
	</body>
</html>