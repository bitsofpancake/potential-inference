<!doctype html>
<html>
	<head>
		<title>Inferring the Mass Distribution of the Milky Way - Casey Chu</title>
		<link href="poster.css" type="text/css" rel="stylesheet" />
		<link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.3.0/katex.min.css" type="text/css" rel="stylesheet" />
	</head>
	<body>
		<header>
			<h1>Inferring the Mass Distribution of the Milky Way</h1>
			<div>Casey Chu, Yoram Lithwick, Fabio Antonini</div>
		</header>
		
		<main>			
			<article>
				<h2>How do we measure something we can't see?</h2>
				
				<p>Astrophysicists generally accept that there is a massive but invisible halo of dark matter around most galaxies. <!--However, the nature of this dark matter is largely unknown. One natural place to start investigating these dark matter halos is our own Milky Way.--> But how do we study something we can't see?</p>

				<p>One way to study dark matter is to observe its gravitational effect on visible objects: stars. And we're in luck, because the spacecraft Gaia is currently observing the movement of one billion stars the Milky Way. These movements contain large amounts of statistical information about the gravitational potential they are traveling in. If we had knew this gravitational potential, then we could find the distribution of matter in the Milky Way, using Poisson's equation.</p>
				
				<p>We've created a simple, numerical algorithm to extract the gravitational potential from the data. Given a set of observed positions and velocities of particles (stars), we are able to infer the potential in which they are traveling.</p>
			</article>
		
			<article>
				<h2>The fundamental assumption: phase-mixing</h2>
				
				<p>The algorithm we developed relies on the system being <em>phase-mixed</em>. Suppose we have 200 particles initially close together in phase space. What happens if they are released in a potential of, say, <var>\Phi(x) = \frac{1}{2}|x|^\alpha</var>, for <var>\alpha = 1.5</var>?</p>
				
				<figure>
					<!--video controls>
						<source src="images/phase_mixing.webm" type="video/webm" />
					</video-->
					<img src="images/evolution_0.svg" />
					<img src="images/evolution_1.svg" />
					<img src="images/evolution_2.svg" />
					<img src="images/evolution_3.svg" />
					<img src="images/evolution_4.svg" />
					<img src="images/evolution_5.svg" />
					<figcaption>The phase-mixing of 200 particles.</figcaption>
				</figure>
				
				<p>Notice that as time progresses, the initial configuration is lost. The particles approach a configuration that is macroscopically steady-state, or phase-mixed.</p>
				
				<p>Importantly, notice how the <em>same</em> set of particles evolve to <em>different</em> steady-state "shapes" when they are evolved under different potentials (e.g., different values of <var>\alpha</var>).</p>
				
				<figure>
					<img src="images/evolved_1.5.svg" />
					<img src="images/evolved_1.8.svg" />
					<img src="images/evolved_2.5.svg" />
					<figcaption>Steady-state configurations for different potentials.</figcaption>
				</figure>
				
				<p>This property, that different potentials produce different steady-state configurations, will turn out to be crucial to our method.</p>

			</article>
			
			<article>
				<h2>The insight behind the inference algorithm</h2>
				
				<figure class="float" style="width: 360px; margin-top: 0.75em">
					<img src="images/unknown.svg" />
					<figcaption>A sample data set: particles observed from an unknown potential.</figcaption>
				</figure>
				
				<p>Suppose that we are given the positions and velocities of particles taken from an unknown potential. Our aim is to guess which potential these particles come from. We may assume that they are drawn from a phase-mixed system.</p>

				<p>Our algorithm relies on the following insight. Let's assume we know that the particles we observe are in a steady-state configuration. Then if we evolve them under the correct potential, they will remain in the same, steady-state configuration. Conversely, if we evolve them under an incorrect potential, they will evolve towards a different configuration!</p>
				
				<p>Then one algorithm to find the correct potential is to simply to guess a bunch of different potentials, evolve the observed particles under each of these trial potentials, and see which potential best preserves the original configuration. The following figure illustrates the evolution of the particles in Figure 3 under different potentials.</p>
				
				<figure>
					<!--
					<video controls loop style="width: 100%">
						<source src="images/evolution.webm" type="video/webm" />
					</video>-->
					<img src="images/comparison0_1.5.svg" />
					<img src="images/comparison0_1.8.svg" />
					<img src="images/comparison0_2.5.svg" />
					<img src="images/comparison1_1.5.svg" />
					<img src="images/comparison1_1.8.svg" />
					<img src="images/comparison1_2.5.svg" />
					<figcaption>The evolution of the observed particles under different potentials.</figcaption>
				</figure>
				
				<p>In this simple example, the particles most likely come from an <var>\alpha = 1.5</var> potential, because the configuration of the particles evolved under that potential most resembles the original, observed distribution.</p>
			</article>
			
			<!--article>
				<h2>Mathematical derivation</h2>
				
				<p>Rather than simply choosing the best potential by eye, let us quantify how good a trial potential is, i.e. how close an evolved configuration is to the observed particles. Let's assign a "likelihood" score to each trial potential, with higher scores corresponding to closer configurations.</p>
				
				<p>
					First, we define a function that encodes the distribution of our observed particles after having been evolved for a time <var>t</var> under a potential <var>\Phi</var>. We use a technique called <a href="https://en.wikipedia.org/wiki/Kernel_density_estimation" target="_blank">kernel density estimation</a> to approximate the phase-space density at time <var>t</var>; define a function <var>f</var> to be
					<code>f(x,v;t \,|\, \Phi) = \sum_i K(x_i(t) - x)\, K(v_i(t) - v),</code>
					where <var>x_i(t)</var> and <var>v_i(t)</var> denote the position and velocity of the <var>i</var>th particle evolved to time <var>t</var> under the potential <var>\Phi</var>, and <var>K(\cdot)</var> is a <em>kernel</em>, a function that is non-zero only around <var>0</var>. For example, a typical kernel is a Gaussian centered at <var>0</var>. The result is that this function <var>f(x,v;t\,|\,\Phi)</var> gives an approximation to the phase-space density of particles at <var>x</var> and <var>v</var> and time <var>t</var>.
				</p>
				
				<p>
					Next, we define a time-averaged version of <var>f</var>:
					<code>f(x,v \,|\, \Phi) = \frac{1}{T}\int_0^T f(x,v;t\,|\,\Phi) \,dt.</code>
					This approximates the steady-state phase-space density of particles evolved under a potential <var>\Phi</var>.
				</p>
				
				<p>If <var>f</var> is properly normalized, we can treat this density function as a probability distribution function. Then the probability of observing the positions and velocities we observed assuming a particular potential is
					<code>
						\Pr(x_1,v_1,\ldots,x_n,v_n\,|\,\Phi) = \prod_i f(x_i, v_i \,|\, \Phi),
					</code>
					assuming that the particles were drawn independently.
				</p>
				
				<p>This allows us to assign a score to different trial potentials, based on our observed data, using <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem" target="_blank">Bayes' theorem</a>:
					<code>
						\Pr(\Phi \,|\, x_1,v_1,\ldots,x_n,v_n) \propto \Pr(\Phi)\,\Pr(x_1,v_1,\ldots,x_n,v_n\,|\,\Phi).
					</code>
					The factor of <var>\Pr(\Phi)</var> is called the <em>prior distribution</em> of <var>\Phi</var>, which is negligible in many cases. This final function is called the <em>posterior distribution</em> of <var>\Phi</var> (or simply, the posterior), and it satisfies our original goal: it's greatest for the most probable trial potentials!
				</p>
			</article-->
			<article>
				<h2>The likelihood function</h2>
				<p>Instead of choosing the best potential by eye, we can construct a function to quantify how good a trial potential is. Let <var>x_1</var>, <var>v_1</var>, <var>\ldots</var>, <var>x_n</var>, <var>v_n</var> be a set of <var>n</var> observed positions and velocities. Then the <em>likelihood</em> that these observations came from a particular potential <var>\Phi</var> is
					<code>
						L(\Phi \,|\, x_1,v_1,\ldots,x_n,v_n) = \prod_i f(x_i, v_i \,|\, \Phi),
					</code>
					where we've defined
					<code>
						f(x,v \,|\, \Phi) = \frac{1}{T}\int_0^T\sum_i K(x_i(t) - x)\,K(v_i(t) - v) \,dt,
					</code>
					where <var>x_i(t)</var> and <var>v_i(t)</var> denote the position and velocity of the <var>i</var>th particle evolved to time <var>t</var> under the potential <var>\Phi</var>, and <var>K(\cdot)</var> is a <em>kernel function</em>, e.g. a Gaussian centered at <var>0</var>. This function is greatest for potentials that preserve the original configuration.
				</p>
			</article>
			
			<article>
				<h2>Summary of the algorithm</h2>
				
				<p>Our algorithm to infer the potential from a set of observed positions and velocities is as follows.</p>
				
				<ol>
					<li><em>Guess a trial potential</em> by choosing a set of values for the parameters of a potential. One intelligent way of choosing parameters is using the Metropolis-Hastings algorithm.</li>
					<li><em>Calculate the likelihood</em> of observing the data under the chosen potential, according to the formula in the previous section.</li>
					<li><em>Repeat</em> steps 1&ndash;2 indefinitely. When satisfied, we can report either the single set of parameters with the maximum likelihood, or a range of parameter values with high likelihoods.</li>
				</ol>
			</article>
			
			<article>
				<h2>Preliminary results</h2>
				
				<p>We have tested the algorithm for the two-dimensional <em>logarithmic potential</em> given by
					<code>\Phi(x,y) = \log(x^2 + \frac{y^2}{q^2} + R_c^2),</code>
					where <var>q</var> and <var>R_c</var> are parameters that describe the shape of the potential. It is a simple model for real galaxies.</p>
				
				
				<figure class="float" style="width: 450px">
					<img src="images/logarithmic.svg" />
					<figcaption>A contour plot of the likelihood of the parameters. Red is higher; contours are at <var>2^{-2^i}</var> for <var>i=0,\ldots,13</var>.</figcaption>
				</figure>
				<!--figure style="width: 400px">
					<video controls loop style="width: 100%">
						<source src="images/logarithmic_potential.webm" type="video/webm" />
					</video>
					<figcaption>"Stars" in a logarithmic potential.</figcaption>
				</figure-->
				
				<p>We simulated mock data from this potential and tested the inference algorithm on the resulting "observations." The results for <var>n = 10^4</var> particles and true parameters of <var>q^2=0.8</var> and <var>R_c^2=1.5</var> are shown in the contour plot to the right.</p>
				
				<p>The likelihood correctly peaks near the true values of the parameters, meaning that the algorithm is successful!</p>
			</article>
			
			<article>
				<h2>Advantages and future work</h2>
				
				<p>Our method has two novel advantages:
					<ul>
						<li><b>General:</b> This algorithm requires only that the particles are in steady-state, whereas older methods require improbable assumptions, e.g. that the potential is <em>Liouville-integrable</em>.</li>
						<li><b>Intuitive:</b> It has an intuitive interpretation in terms of phase-mixing.</li>
					</ul>
				</p>
				
				<p>
					Nevertheless, there are several challenges that should be addressed before applying the algorithm to the Gaia data:
					<ul>
						<li><b>Computation time:</b> An application to <var>10^9</var> particles, although feasible, currently requires a large supercomputer cluster.</li>
						<li><b>Noise:</b> The likelihood function is currently quite noisy, which may prevent accurate inference of parameters.</li>
						<li><b>Lack of error bounds:</b> It is currently unclear how to accurately bound the error of the estimated paramters.</li>
					</ul>
				</p>
			</article>
		</main>
				
			<footer style="font-size: 0.5em; text-align: center; color: rgba(255, 255, 255, 0.75); position: absolute; bottom: 0; width: 100%; margin: 2em;">
				This material is based upon work supported by the National Science Foundation under Grant No. AST-1359462, a Research Experiences for Undergraduates (REU) grant awarded to CIERA at Northwestern University. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.
			</footer>
		
		<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.3.0/katex.min.js"></script>
		<script type="text/javascript">
			[].forEach.call(document.querySelectorAll('var, code'), function (el) {
				katex.render(el.innerHTML, el, { displayMode: el.tagName === 'CODE' });
			});
		</script>
		<script type="text/javascript" src="http://smartquotesjs.com/src/smartquotes.min.js"></script>
	</body>
</html>